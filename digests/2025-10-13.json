[
  {
    "id": "199db5dcbf525ab3",
    "from": "Joshua Clear <aiweeklydotcom@mail.beehiiv.com>",
    "subject": "Elon X A.I Is Secretly Building the Next Big Thing in A.I",
    "date": "2025-10-13T02:19:40.000Z",
    "text": "### The Gold standard for AI news\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90b995bd-d2c2-419e-bdd7-fd452c09b81f/Get_the_AI_news_that_matters_No_hype__just_facts_v1.jpg?t=1756241854)\r\nFollow image link: (https://magic.beehiiv.com/v1/faa6a747-8c1c-43c1-8155-91aa43268f01?email=themnewsandstuff@gmail.com&redirect_to=https%3A%2F%2Fwww.superhuman.ai%2Fc%2Fconfirmation%3Fmagiclink_subscription&utm_source=beehiiv&utm_campaign=VPSLCCALRN&redirect_delay=3&_bhiiv=opp_285c3977-7978-4c00-b85f-5286379ea7b3_d22f5b49&bhcl_id=f328cc66-34c4-420b-8de4-188b2f315a0a_1358dcaa-ca62-4a3e-96cd-c5ff13ec4abf_6234f2ce-90fd-4539-b098-42f6c1e01492)\r\nCaption: \r\n\r\nAI keeps coming up at work, but you still don't get it? \r\n\r\nThat's exactly why 1M+ professionals working at Google, Meta, and OpenAI read [Superhuman AI](https://magic.beehiiv.com/v1/faa6a747-8c1c-43c1-8155-91aa43268f01?email=themnewsandstuff@gmail.com&redirect_to=https%3A%2F%2Fwww.superhuman.ai%2Fc%2Fconfirmation%3Fmagiclink_subscription&utm_source=beehiiv&utm_campaign=VPSLCCALRN&redirect_delay=3&_bhiiv=opp_285c3977-7978-4c00-b85f-5286379ea7b3_d22f5b49&bhcl_id=f328cc66-34c4-420b-8de4-188b2f315a0a_1358dcaa-ca62-4a3e-96cd-c5ff13ec4abf_6234f2ce-90fd-4539-b098-42f6c1e01492) daily. \r\n\r\nHere's what you get:\r\n\r\n* Daily AI news that matters for your career - Filtered from 1000s of sources so you know what affects your industry.\r\n\r\n* Step-by-step tutorials you can use immediately - Real prompts and workflows that solve actual business problems.\r\n\r\n* New AI tools tested and reviewed - We try everything to deliver tools that drive real results.\r\n\r\n* All in just 3 minutes a day\r\n\r\n[Join 1M+ pros](https://magic.beehiiv.com/v1/faa6a747-8c1c-43c1-8155-91aa43268f01?email=themnewsandstuff@gmail.com&redirect_to=https%3A%2F%2Fwww.superhuman.ai%2Fc%2Fconfirmation%3Fmagiclink_subscription&utm_source=beehiiv&utm_campaign=VPSLCCALRN&redirect_delay=3&_bhiiv=opp_285c3977-7978-4c00-b85f-5286379ea7b3_d22f5b49&bhcl_id=f328cc66-34c4-420b-8de4-188b2f315a0a_1358dcaa-ca62-4a3e-96cd-c5ff13ec4abf_6234f2ce-90fd-4539-b098-42f6c1e01492)\r\n\r\n# The $100 Trillion Race Nobody's Talking About: Why Elon Musk Just Hired Nvidia's Secret Weapon\r\n\r\nListen, while everyone's busy arguing about whether ChatGPT can write college essays or destroy humanity, something way more consequential is happening. Elon Musk just poached two of Nvidia's top AI researchers?Zeeshan Patel and Ethan He?and barely anyone noticed. But here's the kicker: these aren't just any engineers. They're specialists in something called \"world models,\" and if you haven't heard that term yet, buckle up, because it's about to reshape everything from video games to your next car to whether we ever get actual useful robots.\r\n\r\nThe market opportunity? Try $100 trillion. Yeah, with a T.\r\n\r\n## What the Hell Are World Models Anyway?\r\n\r\nOkay, so you know how ChatGPT is pretty good at stringing words together but has absolutely no idea what gravity is or how a ball bounces? That's because large language models are basically sophisticated pattern-matching machines trained on text. They've read the entire internet, but they've never actually _experienced_ anything. They don't know that if you drop a cup, it falls. They can't predict what happens when you push a door or throw a ball.\r\n\r\nWorld models are different. These are AI systems that understand physics, causality, and how objects actually behave in space and time. They're trained on video footage, robotic sensor data, and massive simulated environments?not just text and images. The goal is to give AI what researchers call \"physical intuition.\"\r\n\r\nThink about how you navigate the world. You don't consciously calculate trajectories when you catch a ball?you just _know_ where it's going to be. That's intuitive physics, and it's something humans develop as toddlers. World models are attempting to replicate that capability in AI systems.\r\n\r\nIBM's Research Director Juan Bernab?-Moreno describes them as systems that \"form internal representations that capture structure, dynamics and causal relationships.\" In plain English: these AIs are building mental maps of how reality works, not just memorizing text patterns.\r\n\r\n## Why This Matters More Than You Think\r\n\r\nHere's what nobody's really grasping yet: the jump from language models to world models is potentially bigger than the jump from basic algorithms to language models.\r\n\r\nCurrent AI is stuck in the digital realm. It can write code, generate images, answer questions?all valuable stuff. But it fundamentally cannot interact with the physical world in any meaningful way. ChatGPT doesn't know what happens if you stack three boxes and put a bowling ball on top. It can guess based on text it's read, but it doesn't _understand_ the physics.\r\n\r\nWorld models change that equation entirely. Suddenly you're not just predicting the next word in a sentence?you're predicting the next _state of reality_. You're simulating forward in time. You're understanding cause and effect in three-dimensional space.\r\n\r\nAnd once you can do that? Well, then you can:\r\n\r\n* Train robots that don't need millions of trial-and-error attempts to learn basic tasks\r\n\r\n* Create autonomous vehicles that actually understand how pedestrians and other cars behave\r\n\r\n* Generate entire video game worlds that operate according to consistent physical laws\r\n\r\n* Design products in simulation that will actually work in reality\r\n\r\n* Build AI agents that can accomplish complex, multi-step tasks in dynamic environments\r\n\r\nThe thing is, this isn't just incrementally better AI. It's a fundamental category shift from software intelligence to something that can operate in the physical world.\r\n\r\n## The Talent Heist That Reveals Everything\r\n\r\nSo back to Musk's hiring spree. Zeeshan Patel and Ethan He aren't just good engineers?they're veterans of Nvidia's Omniverse platform, which is essentially the premier testing ground for world model development. Omniverse is where companies build physics-accurate simulations for training AI systems, from manufacturing robots to autonomous vehicles.\r\n\r\nWhen xAI hired these guys, they didn't just acquire talent. They acquired institutional knowledge about:\r\n\r\n* How to build physics simulations at massive scale\r\n\r\n* How to optimize training pipelines for multimodal data (video, sensor readings, spatial information)\r\n\r\n* How to integrate hardware and software for real-time AI processing\r\n\r\n* What actually works versus what sounds good in papers\r\n\r\nThis is technology transfer, straight up. And it reveals xAI's strategy: they're not trying to build a slightly better chatbot. They're going all-in on world models as the path to artificial general intelligence (AGI).\r\n\r\n## The $20 Billion War Chest\r\n\r\nHere's where it gets wild. xAI just closed a $20 billion funding round?one of the largest in tech history. Nvidia itself is investing up to $2 billion in equity. The structure is bonkers: roughly $7.5 billion in equity and up to $12.5 billion in debt, organized through a special purpose vehicle that will purchase Nvidia processors and lease them back to xAI for five years.\r\n\r\nThis isn't just investment capital. This is an infrastructure play.\r\n\r\nThat money is funding xAI's Colossus 2 data center in Memphis, which currently runs 200,000 GPUs and is projected to scale to one million GPUs. For context, that's the world's largest AI training cluster by a massive margin. Training world models requires absolutely stupid amounts of compute power?way more than language models?because you're processing video, simulating physics, and modeling complex temporal relationships across massive datasets.\r\n\r\nNvidia's Vice President of Omniverse and Simulation Technology, Rev Lebaredian, has projected the market for world models could reach $100 trillion. That's not a typo. The reasoning: world models unlock AI applications across autonomous driving, robotics, manufacturing, healthcare, gaming, industrial automation, and scientific research. Basically every sector where AI needs to understand and interact with physical reality.\r\n\r\n## The Gaming Gambit\r\n\r\nNow here's where Musk's strategy gets clever. xAI is planning to debut world models first in gaming applications. Musk has publicly committed to releasing \"a great AI-generated game before the end of next year.\"\r\n\r\nWhy gaming? Three reasons:\r\n\r\n**First**, gaming is a contained environment where \"hallucinations\" in the physics don't kill anyone. If your AI-generated game world has slightly wonky physics, gamers will just think it's a weird design choice. But if your autonomous vehicle hallucinates a pedestrian crossing, people die.\r\n\r\n**Second**, gamers will pay for experiences, and they're early adopters who'll provide tons of feedback. It's a perfect testing ground with built-in monetization.\r\n\r\n**Third**?and this is the real insight?the technology stack for generating immersive 3D game environments is fundamentally the same as what you need for robotics and autonomous systems. If you can create a world model sophisticated enough to generate a compelling game world with consistent physics and interactive objects, you've essentially built the foundation for real-world robotics applications.\r\n\r\nAs one industry observer put it: the same technology powering interactive game environments will eventually enable robotic systems to understand and navigate real-world spaces.\r\n\r\nOf course, not everyone's buying it. Larian Studios' Michael Douse (the folks behind Baldur's Gate 3) has been openly skeptical, arguing that gaming needs \"more expressions of worlds that folks are engaged with\" rather than \"mathematically produced, psychologically trained gameplay loops.\" Which, fair. But that criticism kind of misses the point?xAI isn't trying to replace human creativity in game design. They're trying to prove the underlying world model technology works.\r\n\r\n## The Race Nobody Saw Coming\r\n\r\nHere's what's actually happening right now, while everyone's distracted by GPT-5 rumors and whether AI will take your job: every major AI lab has pivoted hard toward world models.\r\n\r\nGoogle DeepMind just released Genie 3, their latest world model research. Meta's pouring resources into world model development. Nvidia's Cosmos platform can process and label 20 million hours of video in two weeks using their Blackwell architecture?a task that would take three years on traditional CPUs. OpenAI is rumored to be working on world models behind the scenes.\r\n\r\nThe shift is happening because everyone's hitting the same wall: language model improvements are slowing down. We're seeing diminishing returns from just making models bigger and feeding them more text. The easy gains are done.\r\n\r\nWorld models represent the next frontier. As AI researcher Yann LeCun (one of the godfathers of deep learning) has argued, world models may be the \"missing link for human-level AI\" because they enable common sense reasoning, uncertainty handling, and long-term planning capabilities that language models simply cannot develop.\r\n\r\nBut here's the reality check: LeCun also estimates achieving mature world models capable of human-level intelligence might take another decade. The technical challenges are enormous.\r\n\r\n## The Trillion-Dollar Obstacles\r\n\r\nLet's talk about what makes world models so damn hard to build:\r\n\r\n**Computational requirements are insane.** Training these models needs massive amounts of diverse, high-quality data?video, robotics sensor readings, simulated environments?all processed simultaneously. Even with xAI's million-GPU cluster, we're talking about training runs that take months and cost tens of millions of dollars.\r\n\r\n**The reality gap is real.** Just because your AI can simulate physics accurately doesn't mean it understands real-world edge cases. Current systems are still prone to \"hallucinations\" in their simulations?generating physics that looks plausible but violates actual physical laws. Getting from 99% accurate to 99.99% accurate matters enormously when you're controlling a robot or autonomous vehicle.\r\n\r\n**Data curation is a nightmare.** You need diverse, representative datasets spanning countless scenarios. Nvidia's Omniverse helps by generating synthetic training data, but there's still a massive challenge in ensuring your simulated training environments actually transfer to real-world applications.\r\n\r\n**Nobody's really cracked long-term planning yet.** Current world models can simulate forward a few seconds reasonably well. But complex tasks requiring planning over minutes or hours? That's still mostly unsolved.\r\n\r\n## The AGI Endgame\r\n\r\nOkay, so let's zoom out. Why is Musk going all-in on this?\r\n\r\nBecause if world models work?if you can build AI systems with genuine physical understanding and causal reasoning?you've essentially solved the core remaining barrier to AGI. Language models gave us superhuman text processing. Computer vision gave us superhuman image recognition. But neither gave us general intelligence because neither understands how the world actually works.\r\n\r\nMusk has made some pretty wild claims about Grok 4 (xAI's next-generation model), suggesting it might \"discover new technologies as soon as later this year\" and potentially \"discover new physics within two years.\" Take those predictions with approximately one ton of salt?Musk is not known for conservative timelines. But they reveal the ambition: xAI is betting that world models plus massive compute plus aggressive talent acquisition equals a genuine shot at AGI.\r\n\r\nThe convergence is real: unprecedented computational infrastructure, advanced algorithms improving rapidly, and more capital than any AI project in history. If there's ever been a moment where AGI seems plausible in the next 5-10 years rather than 50-100, this is it.\r\n\r\n## What This Means for You (Eventually)\r\n\r\nHere's where the rubber meets the road. If world models work, we're looking at:\r\n\r\n**Robotics that actually scale.** Current robots are expensive, fragile, and require massive programming for specific tasks. World models could enable genuinely general-purpose robots that can learn new tasks quickly and work reliably in unstructured environments. Think less \"robot arm repeatedly welding the same joint\" and more \"robot assistant that can navigate your house, understand natural language instructions, and accomplish novel tasks.\"\r\n\r\n**Autonomous everything.** Self-driving cars have been \"five years away\" for fifteen years now. World models might actually get us there by enabling vehicles that genuinely understand how humans behave, can predict edge cases, and plan routes accounting for complex urban environments.\r\n\r\n**Scientific acceleration.** AI systems that understand physics could simulate experiments, predict outcomes, and even suggest novel approaches to problems in materials science, drug discovery, and engineering. Musk's claim about Grok discovering \"new physics\" is probably hyperbole, but AI-assisted scientific discovery is genuinely plausible.\r\n\r\n**Gaming and entertainment.** Near-term, we'll probably see AI-generated games and interactive experiences that feel genuinely responsive rather than scripted. Longer-term, imagine VR experiences where the AI understands physics well enough to let you interact naturally with virtual objects.\r\n\r\nBut here's the thing: all of this is still speculative. World models are promising as hell, but they're not solved technology. We're in the early innings, not the late game.\r\n\r\n## The Real Story\r\n\r\nWhat's actually happening right now is a massive strategic bet across the entire AI industry. Companies are pivoting from \"let's make language models bigger\" to \"let's make AI understand reality.\" That shift is happening because the easy gains from scaling language models are done, and everyone's looking for the next exponential improvement curve.\r\n\r\nxAI's advantage is simple: they have Musk's vision (for better or worse), Nvidia's backing and technology transfer, $20 billion in funding, the world's largest training cluster, and they're moving fast. They're also starting fresh without legacy systems or business models to protect.\r\n\r\nTheir disadvantage? They're competing against Google DeepMind (decades of robotics research), Meta (massive resources and data), OpenAI (head start on general AI research), and basically every serious AI lab on the planet. This isn't a race with one winner?it's an arms race where multiple competitors might crack significant breakthroughs.\r\n\r\nThe $100 trillion figure thrown around by Nvidia? That's not just hype. If world models actually work at scale, they unlock AI applications across essentially every industry that involves physical products or processes. Manufacturing, agriculture, construction, healthcare, transportation, logistics?the list goes on. We're talking about extending AI from software tasks into the physical economy.\r\n\r\nBut we're also talking about a technology that doesn't fully exist yet. World models in 2025 are roughly where language models were in 2018?promising as hell, improving rapidly, but not yet ready for most real-world applications.\r\n\r\n## The Bottom Line\r\n\r\nElon Musk hiring two Nvidia researchers doesn't sound like much. But when you understand what they're building, why they're building it, and how much capital is flowing into world models right now, it reveals something fundamental: the AI race just entered a completely new phase.\r\n\r\nWe spent the last three years obsessed with whether chatbots can pass college exams. The next three years will be about whether AI can understand and navigate physical reality. That's a way more consequential question.\r\n\r\nAnd if you're wondering whether to pay attention to world models? Well, Nvidia's betting $2 billion that you should. Musk's betting his entire AI strategy on it. Every major tech company is pivoting hard toward it.\r\n\r\nThe $100 trillion race is on. Most people just don't know they're watching it yet.\r\n\r\n???????????????????????????\r\n\r\n**Links and Shit:**\r\n\r\nFor the tech-obsessed: Nvidia's Omniverse platform is genuinely worth exploring?it's where most of this world model development is actually happening.\r\n\r\nFor the skeptics: Gary Marcus on Twitter has been providing good counterpoints to world model hype, reminding everyone that AI has failed to deliver on grand promises before.\r\n\r\nFor the terrified: World models enabling general-purpose robots is either humanity's greatest achievement or the beginning of the robot apocalypse, depending on your disposition. Place your bets accordingly.\r\n\r\n\r\n???\r\n\r\nYou are reading a plain text version of this post. For the best experience, copy and paste this link in your browser to view the post online:\r\nhttps://www.aiweekly.com/p/elon-x-a-i-is-secretly-building-the-next-big-thing-in-a-i"
  },
  {
    "id": "199da914fcd247fa",
    "from": "The Neuron <theneuron@newsletter.theneurondaily.com>",
    "subject": "? Figure 03 = the Model T of robots",
    "date": "2025-10-12T22:36:19.000Z",
    "text": "View image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/f79b2160-db9f-4c82-96dc-52d485b8f511/The_Neuron_Header_-_10.12.2025.png?t=1760304133)\r\nCaption: \r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/3f6a4c08-a1ac-47b7-8862-2001fa0872f7/In_partnership_with...__43_.png?t=1760304182)\r\nFollow image link: (https://rippling.registration.goldcast.io/webinar/6cbcb797-6496-4f3e-9a42-9d4b9d8b799e?utm_source=newsletter&utm_medium=email&utm_program=experimental-engagement&utm_term=dg-vcb&utm_campaign=US_VCB_Linear Webinar_10/15/25_Neuron Newsletter&utm_product=core_hr&utm_content=Neuron Newsletter)\r\nCaption: \r\n\r\nWelcome, humans. \r\n\r\nEver wonder why your company has so many managers? Aparna Chennapragada, Microsoft's CPO of AI Experiences, has a theory: [they're human translators](https://aparnacd.substack.com/p/most-work-is-translation). \r\n\r\nHer recent essay argues that most work isn't actually creating or executing; it's _translating_. Engineers translate specs into code. Analysts translate data into charts. Managers translate strategies into updates. PMs translate customer needs into requirements. The org chart? It's basically a pyramid-shaped translation machine, with humans in the middle carrying information up and down.\r\n\r\nNow here?s where AI comes in: language models, like ChatGPT, are the first ?universal translators? for work. They can turn a 20-page report into a one-pager, a meeting into a brief, a spreadsheet into a chart, or requirements into code scaffolding instantly, for _nearly_ free. When translation costs collapse to zero, you don't need thick middle layers of human translators anymore. The pyramid flattens into what she calls a ?backbone.?\r\n\r\nThe post gots [lots of shares on LinkedIn](https://www.linkedin.com/posts/aparnacd_this-piece-by-aparna-chennapragada-goes-in-activity-7382875137018220544-EGGx), and she responded by explaining this is why she's building [Researcher at Microsoft](https://www.microsoft.com/en-us/microsoft-365/blog/2025/03/25/introducing-researcher-and-analyst-in-microsoft-365-copilot/). She wants to create an AI that gives every employee CEO-level insights by reasoning across your entire company's knowledge and the web. Think of it as that backbone layer, but productized. \r\n\r\n_As for what this all means for middle management ?translator? jobs? depends on whether or not you consider permanently being ?Out of Office? a promotion? _\r\n\r\n**Here?s what happened in AI today: **\r\n\r\n1. Figure debuts its 03 mass-production home robot for 2026. \r\n\r\n2. Google Nano Banana Image gen lands in Search/Lens for Android in the U.S.\r\n\r\n3. India launched nationwide pilot to shop and pay via AI assistants.\r\n\r\n4. Spotify + ChatGPT launch new integration for instant playlist/podcast recs.\r\n\r\nAdvertise in The Neuron here (https://info.technologyadvice.com/advertise-with-the-neuron)\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/484260c4-b2a0-4171-87e0-e84a8ad1b48a/image.png?t=1757726617)\r\nCaption: \r\n\r\n## Is Figure 03 the ?Model T? moment for robots?? \r\n\r\nYoutube: Introducing Figure 03 (https://youtu.be/Eu5mYMavctM?si=lqXZx2uvzMp9u9Ck)\r\n\r\nFigure AI just dropped [Figure 03](https://www.figure.ai/news/introducing-figure-03), and holy moly: this might be the first humanoid robot actually built for your living room. \r\n\r\nThink of it as [the Model T of robots](https://newatlas.com/ai-humanoids/watch-figure-03-model-t-robots/). The big difference from previous versions? This bad boy was designed from the ground up for mass production. No more hand-built prototypes that cost a gazillion dollars each.\r\n\r\n**Here's the deal:** [Figure 03 can fold laundry](https://youtu.be/Eu5mYMavctM?si=lqXZx2uvzMp9u9Ck), load your dishwasher, clear tables, and even water plants. It's covered in soft, washable fabric (think knit sweater vibes) instead of cold hard metal, making it 9% lighter and way less likely to accidentally clothesline you in the hallway.\r\n\r\n**What makes it tick?** Figure's proprietary AI system [called Helix](https://www.figure.ai/news/helix). It?s basically a vision-language-action system that let it learn new tasks by watching humans. The robot learned to fold towels from just 80 hours of video footage (_almost as much time as your Nephew spends learning TikTok dances_). \r\n\r\n**The tech upgrades from Figure 02 to 03 are actually wild:**\r\n\r\n* Cameras with 2x frame rate, 60% wider field of view, and 75% less latency.\r\n\r\n* Palm cameras in each hand for close-up viewing (like having eyes in your hands).\r\n\r\n* Tactile fingertip sensors that detect forces as light as 3 grams (the weight of a paperclip).\r\n\r\n* Wireless charging through its feet; just steps onto a charging pad.\r\n\r\n* Better speakers and microphones for voice control.\r\n\r\n**Why this matters:** Figure [raised $1B at a $39B](https://www.figure.ai/news/series-c) valuation from investors including NVIDIA, Jeff Bezos, OpenAI, and Microsoft. They're building a [new factory called BotQ](https://www.figure.ai/news/botq) that'll pump out 12K robots per year initially, targeting 100K over four years.\r\n\r\nOh, and TIME just named it [one of the Best Inventions of 2025](https://time.com/7324233/figure-03-robot-humanoid-reveal/).\r\n\r\n**The reality check:** As flashy as this demo is, this robot isn?t actually ready for home use just yet. CEO Brett Adcock admits they're ?not there yet? and hopes to nail it by 2026. After all, the robot was only [finished a week before the demo](https://www.reddit.com/r/singularity/comments/1o2i66l/figure_03_was_only_ready_a_week_before_the_demo/). And during TIME's visit, the robot kept dropping laundry and couldn't pick it back up. \r\n\r\n_This is something we wondered too: if the robot is carrying a box, and then accidentally drops it, could it react quickly enough to catch it mid-air? That?s the demo we wanna see, Brett!_\r\n\r\n**The debate:** Many roboticists argue humanoid isn't the right form factor. Hexapod robots (think six-legged spiders) might be more versatile for certain tasks, though they're probably further out for consumer use; that said, here?s a [pretty epic one under construction right now](https://www.reddit.com/r/robotics/comments/1o3tm23/testing_our_hexapod/):\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/3122eaad-67a0-4ae3-8f79-11fe8fa8960a/Screenshot_2025-10-12_at_11.01.06_AM.png?t=1760292077)\r\nFollow image link: (https://www.reddit.com/r/robotics/comments/1o3tm23/testing_our_hexapod/)\r\nCaption: \r\n\r\n**Here's the ultimate bet:** if AI scaling laws apply to robotics the same way they did to ChatGPT, we might be closer than we think. Every robot uploads terabytes of data for continuous learning. More data = smarter robots = your dishes finally getting loaded correctly? _and maybe catching that falling plate faster than you can? _\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90cb4fc4-8d6a-426b-b729-df63915eea25/image.png?t=1757726598)\r\nCaption: \r\n\r\n**FROM OUR PARTNERS**\r\n\r\n# From 0 to $1.25B: How Linear grew without over-hiring\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/80321002-c84c-4270-ba8e-7672bc94c7bf/Neuron__2_.png?t=1760285913)\r\nFollow image link: (https://rippling.registration.goldcast.io/webinar/6cbcb797-6496-4f3e-9a42-9d4b9d8b799e?utm_source=newsletter&utm_medium=email&utm_program=experimental-engagement&utm_term=dg-vcb&utm_campaign=US_VCB_Linear Webinar_10/15/25_Neuron Newsletter&utm_product=core_hr&utm_content=Neuron Newsletter)\r\nCaption: \r\n\r\nCursor hit $10B with 60 people. Linear serves 15,000+ customers with 80.\r\n\r\nThe future of scaling isn?t about headcount...it?s about efficiency.\r\n\r\nJoin Cristina Cordova (COO, Linear; ex-Stripe, Notion) for [Rippling?s ](https://rippling.registration.goldcast.io/webinar/6cbcb797-6496-4f3e-9a42-9d4b9d8b799e?utm_source=newsletter&utm_medium=email&utm_program=experimental-engagement&utm_term=dg-vcb&utm_campaign=US_VCB_Linear Webinar_10/15/25_Neuron Newsletter&utm_product=core_hr&utm_content=Neuron Newsletter)_[First Principles Series](https://rippling.registration.goldcast.io/webinar/6cbcb797-6496-4f3e-9a42-9d4b9d8b799e?utm_source=newsletter&utm_medium=email&utm_program=experimental-engagement&utm_term=dg-vcb&utm_campaign=US_VCB_Linear Webinar_10/15/25_Neuron Newsletter&utm_product=core_hr&utm_content=Neuron Newsletter)__ _as she unpacks how top startups are optimizing for revenue per employee, not vanity growth.\r\n\r\nLearn how to:\r\n\r\n? Build collapsible teams.\r\n\r\n? Identify when it?s really time to hire because ?hiring before you have the signal isn?t scaling, it?s gambling.?\r\n\r\n? Keep craftsmanship alive while scaling fast.\r\n\r\n? Oct 15 | 11 AM PT\r\n\r\n?? Cristina Cordova, COO at Linear\r\n\r\n?? First 25 people to engage during the live session get a limited-edition ?First Principles? dad hat.\r\n\r\n? [[Register Now]](https://rippling.registration.goldcast.io/webinar/6cbcb797-6496-4f3e-9a42-9d4b9d8b799e?utm_source=newsletter&utm_medium=email&utm_program=experimental-engagement&utm_term=dg-vcb&utm_campaign=US_VCB_Linear Webinar_10/15/25_Neuron Newsletter&utm_product=core_hr&utm_content=Neuron Newsletter)\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/31ebd8ab-86d3-46df-aa3d-d61beb2bf385/image.png?t=1757726580)\r\nCaption: \r\n\r\n# Prompt Tip of the Day\r\n\r\nThis [Interactive Prompt Engineering Tutorial](https://github.com/anthropics/prompt-eng-interactive-tutorial) from Anthropic teaches you to craft effective Claude prompts through interactive exercises, from basic structure to advanced techniques like hallucination prevention and industry-specific applications. There?s also a [Google Sheets version](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8/edit?usp=sharing) you can check out here. \r\n\r\nNow, that guide is getting a bit dated, but it?s still worth doing if you?re new to prompting and AI. For a slightly more up to date resource, check out Anthropic?s guide to [Claude 4](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices), or if you prefer using ChatGPT, check out [OpenAI?s prompting guide to GPT 5](https://github.com/openai/openai-cookbook/blob/main/examples/gpt-5/gpt-5_prompting_guide.ipynb). We also recommend you check out Anthropic?s tips on working with [Extended Thinking](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips), which provides tips for working with the smarter version of Anthropic?s models that ?reason? before answering your questions. ChatGPT-5 ?Thinking? has Thinking mode, which is similar but has multiple thinking levels. \r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/30b9fd7f-943c-473d-9573-115ea2ec59d3/image.png?t=1757726560)\r\nCaption: \r\n\r\n# Treats to Try\r\n\r\n1. [Sider](https://sider.ai/) automates research by finding and sorting sources for any topic, highlighting the key information, and generating a detailed report with citations?free trial, then $16/month (though there?s different pricing tiers).\r\n\r\n2. [Reve](https://app.reve.com/) creates images with readable text (type ?coffee shop poster? and get actual words, not scrambled letters) and is apparently a great image editor?free to try. \r\n\r\n3. [Layercode CLI](https://layercode.com/blog/layercode-cli-is-now-available) lets you create voice AI agents with one command that respond in ~50ms across 330+ global locations. Free $100 credit (~1K convo minutes).\r\n\r\n4. [JustPaid](https://www.justpaid.ai/) streamlines your financial operations with automated invoicing, payment tracking, and revenue insights that help identify unbilled usage and growth opportunities.\r\n\r\n5. [Lyra](https://lyra.so/) captures your meeting notes, action items, and follow-ups automatically in real time, turning hours of admin work into minutes and ensuring nothing gets lost in your team's workflow.\r\n\r\n6. [Spotify's ChatGPT integration](https://techcrunch.com/2025/10/10/you-can-now-connect-your-spotify-account-to-chatgpt-heres-how-to-do-it/) connects to ChatGPT so you can say \"create a workout playlist with my top artists\" or \"suggest jazz podcasts\" and get instant, personalized music recommendations?free for all Spotify users.\r\n\r\n7. [Doored](https://www.bemmu.com/doored/) is a game made entirely with Google?s Veo 3, which reminds us of the old-school ?video? games in the 90s that used ?full motion video? (live action footage) and mixed it with gameplay via quick-time events. _Peak CD-ROM vibes._\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/061c0def-d559-4f98-86e5-52c33cdb201c/image.png?t=1757726537)\r\nCaption: \r\n\r\n# Around the Horn\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d609cc93-5195-4ac3-98a2-64687d73ddd5/Screenshot_2025-10-12_at_11.05.07_AM.png?t=1760292320)\r\nFollow image link: (https://x.com/deedydas/status/1977029236390285608)\r\nCaption: [Paper](https://arxiv.org/abs/2510.05016)\r\n\r\n* [Thinking Machines Lab](https://techcrunch.com/2025/10/11/thinking-machines-lab-co-founder-andrew-tulloch-heads-to-meta/) co-founder Andrew Tulloch joined Meta after reportedly turning down a $1.5 billion offer earlier ([rumors say $3.5B](https://x.com/Yuchenj_UW/status/1977222929286119609) but ????).\r\n\r\n* [Apple is close](https://www.cnbc.com/2025/10/10/apple-nears-deal-to-acquire-talent-tech-from-ai-startup-prompt-ai.html) to acquiring computer vision startup Prompt AI that develops human-like sensing technology.\r\n\r\n* [India](https://techcrunch.com/2025/10/09/india-pilots-ai-chatbot-led-e-commerce-with-chatgpt-gemini-claude-in-the-mix/) launched a nationwide pilot enabling consumers to shop and pay directly via AI chatbots, primarily ChatGPT.\r\n\r\n* [Google](https://9to5google.com/2025/10/11/google-lens-ai-mode-nano-banana/) integrated Nano Banana AI image generator into Search and Lens for Android US users.\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/bff2023e-8ab0-4900-b114-dc81110d4b43/image.png?t=1757726520)\r\nCaption: \r\n\r\n**FROM OUR PARTNERS**\r\n\r\n### How a $25M Catalyst Could Bring Robotics Nationwide\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4e700531-a60f-4898-85e1-859c1e7169e1/7_Miso_Partnership-1200x800_092425_002__1_.png?t=1759341469)\r\nFollow image link: (https://invest.misorobotics.com/?utm_source=email&utm_medium=paid-partnership&utm_campaign=partnership185-380_10-01_varc_unitb_33180545100_YJ4ZPRQDHV&_bhiiv=opp_3e094fbe-4ed2-4a95-9079-9d7eeff8e8f5_a2f2203a&bhcl_id=bebc2627-a4f7-4fa5-9ed1-f4dcc8935ab6_1358dcaa-ca62-4a3e-96cd-c5ff13ec4abf_6234f2ce-90fd-4539-b098-42f6c1e01492)\r\nCaption: \r\n\r\nAutomation?s the future, but 71% of execs say _upfront costs_ prevent its adoption. That?s why [Miso Robotics](https://invest.misorobotics.com/?utm_source=email&utm_medium=paid-partnership&utm_campaign=partnership185-380_10-01_varc_unitb_33180545100_YJ4ZPRQDHV&_bhiiv=opp_3e094fbe-4ed2-4a95-9079-9d7eeff8e8f5_a2f2203a&bhcl_id=bebc2627-a4f7-4fa5-9ed1-f4dcc8935ab6_1358dcaa-ca62-4a3e-96cd-c5ff13ec4abf_6234f2ce-90fd-4539-b098-42f6c1e01492)? new $25M hardware financing facility for customers turned heads. Miso?s AI-powered kitchen robots have logged 200k+ hours for brands like White Castle. With this $25M line and [partnerships with NVIDIA, Amazon](https://invest.misorobotics.com/?utm_source=email&utm_medium=paid-partnership&utm_campaign=partnership185-380_10-01_varc_unitb_33180545100_YJ4ZPRQDHV&_bhiiv=opp_3e094fbe-4ed2-4a95-9079-9d7eeff8e8f5_a2f2203a&bhcl_id=bebc2627-a4f7-4fa5-9ed1-f4dcc8935ab6_1358dcaa-ca62-4a3e-96cd-c5ff13ec4abf_6234f2ce-90fd-4539-b098-42f6c1e01492), it?s unlocking quick, flexible adoption of cutting-edge automation. [Invest before Miso?s bonus shares change on 10/9.](https://invest.misorobotics.com/?utm_source=email&utm_medium=paid-partnership&utm_campaign=partnership185-380_10-01_varc_unitb_33180545100_YJ4ZPRQDHV&_bhiiv=opp_3e094fbe-4ed2-4a95-9079-9d7eeff8e8f5_a2f2203a&bhcl_id=bebc2627-a4f7-4fa5-9ed1-f4dcc8935ab6_1358dcaa-ca62-4a3e-96cd-c5ff13ec4abf_6234f2ce-90fd-4539-b098-42f6c1e01492)\r\n\r\n~This is a paid advertisement for Miso Robotics? Regulation A offering. Please read the offering circular at ~~[invest.misorobotics.com](https://invest.misorobotics.com)~~.~\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d104536b-c87c-4975-8d95-4713878e58bf/image.png?t=1757980037)\r\nCaption: \r\n\r\n# Sunday Special \r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/03cbf622-c87f-4320-92b9-788cedd0b9df/Screenshot_2025-10-12_at_11.29.09_AM.png?t=1760293763)\r\nFollow image link: (https://www.reddit.com/r/CursedAI/comments/1o4dwn0/we_have_hit_critical_mass_with_the_ai_now_i_think/)\r\nCaption: Why yes, this is indeed Arnold playing Vanessa Carlton?s ?A Thousand Miles?, we?re so glad you asked! \r\n\r\n* New [findings from Wiley](https://www.theregister.com/2025/10/08/more_researchers_use_ai_few_confident/) shared by Brandon Vigliarolo reveal how AI's widespread adoption among researchers (now at 84%) is colliding with reality; while most report improved efficiency, confidence in AI outperforming humans has plummeted ([report](https://www.wiley.com/content/dam/wiley-com/en/pdfs/explanaitions/explanaitions-mini-report-2025-final-2-1.pdf)).\r\n\r\n* This [honest breakdown from Hex](https://hex.tech/blog/bitter-lessons-building-ai-in-hex-product-management/) explains why overengineering solutions for current AI model limitations is often wasted effort.\r\n\r\n* This [report shows](https://restofworld.org/2025/latin-america-judges-ai-crimes/) Latin American courts face a digital evidence crisis, lacking tools and frameworks to authenticate AI-generated content in criminal cases.\r\n\r\n* The Register's Thomas Claburn analyzed [new data from LayerX](https://www.theregister.com/2025/10/07/gen_ai_shadow_it_secrets/) and revealed that 45% of enterprise employees used unauthorized generative AI tools with 77% admitting to pasting sensitive company data into public chatbots.\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b70b57db-be7a-4f0a-ae01-3624c84b2602/image.png?t=1757726478)\r\nCaption: \r\n\r\n# A Cat?s Commentary\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/1ef1cf1f-54d4-4d85-8675-5db3883f9bd1/A_Cat_s_Commentary_x_2025__39_.png?t=1760304008)\r\nCaption: \r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/c34b113c-46ce-4741-bd8b-d3433150b1cd/image.png?t=1757726495)\r\nCaption: \r\n\r\nThat?s all for today!\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/1c447a95-930e-4cae-8dba-4743efe3ce91/image.png?t=1757305515)\r\nCaption: \r\n\r\n\r\n\r\n\r\n\r\n\r\nView image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/fcb2de4e-45f1-4c1f-8c87-8ef129090e74/image.png?t=1757726426)\r\nCaption: \r\n\r\n\r\n\r\n\r\n???\r\n\r\nYou are reading a plain text version of this post. For the best experience, copy and paste this link in your browser to view the post online:\r\nhttps://www.theneurondaily.com/p/is-this-the-model-t-moment-for-robots"
  }
]